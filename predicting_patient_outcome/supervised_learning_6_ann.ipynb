{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_pickle('../create_SL_data/data_6months.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['patient_number'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['CHR', 'patient_number'], axis=1)  \n",
    "y = data['CHR']                                  \n",
    "\n",
    "patient_numbers = data['patient_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import LeaveOneOut, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "models = {\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {'n_estimators': [50, 100, 200, 300, 500], 'max_depth': [3, 5, 10, 50], 'max_features' : ['sqrt', None]}\n",
    "\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {'n_neighbors': [3, 5, 7, 10], 'weights': ['uniform', 'distance']}\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'params': {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "    },\n",
    "    'LDA': {\n",
    "        'model': LinearDiscriminantAnalysis(),\n",
    "        'params': {'solver': ['svd', 'lsqr']}\n",
    "    }\n",
    "}\n",
    "\n",
    "feature_importances = {name: pd.DataFrame(np.zeros((X.shape[0], X.shape[1])), columns=X.columns) for name in models if name == 'RandomForest'}\n",
    "scores = {name: {'f1_scores': [], 'accuracy_scores': [], 'best_params': []} for name in models}\n",
    "\n",
    "outer_cv = LeaveOneOut()\n",
    "inner_cv = LeaveOneOut()\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(X)):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    for name, config in models.items():\n",
    "        grid_search = GridSearchCV(config['model'], config['params'], cv=inner_cv, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        y_pred = best_model.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        scores[name]['f1_scores'].append(f1)\n",
    "        scores[name]['accuracy_scores'].append(accuracy)\n",
    "        scores[name]['best_params'].append(grid_search.best_params_)\n",
    "\n",
    "        if name == 'RandomForest':\n",
    "            feature_importances[name].iloc[fold_idx, :] = best_model.feature_importances_\n",
    "        \n",
    "    print('fold', fold_idx)\n",
    "\n",
    "results = {}\n",
    "for name in models:\n",
    "    average_f1 = np.mean(scores[name]['f1_scores'])\n",
    "    average_accuracy = np.mean(scores[name]['accuracy_scores'])\n",
    "    results[name] = {'Average F1 Score': average_f1, 'Average Accuracy': average_accuracy, 'Best Parameters': scores[name]['best_params'][-1]}\n",
    "\n",
    "    if name == 'RandomForest':\n",
    "        mean_fi = feature_importances[name].mean(axis=0).sort_values(ascending=False)\n",
    "        results[name]['Feature Importances'] = mean_fi\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f\"{name} Results:\")\n",
    "    for key, value in result.items():\n",
    "        print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestClassifier(n_estimators=50, max_depth=3, max_features='sqrt', random_state=42)\n",
    "model2 = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "model3 = LinearDiscriminantAnalysis(solver='svd')\n",
    "\n",
    "model1.fit(X, y)\n",
    "model2.fit(X, y)\n",
    "model3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=50, max_depth=3, max_features='sqrt', random_state=42)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "coefficients = model.feature_importances_  \n",
    "\n",
    "feature_importance = pd.DataFrame(data={'Feature': X.columns, 'Importance': coefficients})\n",
    "\n",
    "feature_importance['Absolute Importance'] = feature_importance['Importance'].abs()\n",
    "feature_importance = feature_importance.sort_values(by='Absolute Importance', ascending=False)\n",
    "\n",
    "feature_importance.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pool2 = pd.read_pickle('../create_SL_data_pool2/data_6months_an_pool2.pkl')\n",
    "data_pool2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_pool2.drop(['CHR', 'patient_number'], axis=1)  \n",
    "y_test = data_pool2['CHR']  \n",
    "\n",
    "y_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
