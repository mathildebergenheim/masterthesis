{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../cytofdata/pool1_with_annotated_clusters')\n",
    "data.drop('batch', axis=1, inplace=True)\n",
    "\n",
    "data['sample'] = data['patient_number'].astype(str) + \"_\" + data['test_time'].astype(str)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_as_num = {\n",
    "    'PreNeu1'            :18,\n",
    "    'pDC'                :17,\n",
    "    'PreNeu3'            :16,\n",
    "    'NeutrophilsCD25'    :15,\n",
    "    'PreNeu2'            :14,\n",
    "    'NeutrophilsHLA'     :13,\n",
    "    'LinNeg'             :12,\n",
    "    'Doublets'           :11,\n",
    "    'Bcells'             :10,\n",
    "    'HSPCs'              :9,\n",
    "    'NKcells'            :8,\n",
    "    'Tc'                 :7,\n",
    "    'Th'                 :6,\n",
    "    'Monocytes'          :5,\n",
    "    'Basophils'          :4,\n",
    "    'Eosinophils'        :3,\n",
    "    'NeutrophilCD16neg'  :2 ,\n",
    "     'PreNeu'            :1 ,\n",
    "     'Neutrophils'       :0 \n",
    "}\n",
    "\n",
    "data['cluster'] = data['cluster'].map(cluster_as_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "internal_and_external = ['89Y_CD45', \n",
    "                '111Cd_CD3', \n",
    "                '112Cd_CD34',\n",
    "                '113Cd_CD123', \n",
    "                '114Cd_CD66b', \n",
    "                '116Cd_HLA-DR', \n",
    "                '141Pr_CD38', \n",
    "                '142Nd_cCaspase3', \n",
    "                '143Nd_pCRKL Y207', \n",
    "                '144Nd_pTyr',\n",
    "                '145Nd_CD4', \n",
    "                '146Nd_CD49d', \n",
    "                '147Sm_CD20', \n",
    "                '148Nd_CD16', \n",
    "                '149Sm_CD25',\n",
    "                '150Nd_pSTAT5 Y694', \n",
    "                '151Eu_pSTAT3 S727', \n",
    "                '152Sm_CD13',\n",
    "                '153Eu_pSTAT1 Y701', \n",
    "                '154Sm_CD45RA', \n",
    "                '155Gd_CD27',\n",
    "                '156Gd_pp38 T180Y182', \n",
    "                '157Gd_CD8a', \n",
    "                '158Gd_pSTAT3 Y705',\n",
    "                '159Tb_pMAPKAPK T334', \n",
    "                '160Gd_CD14', \n",
    "                '161Dy_CD26', \n",
    "                '162Dy_FoxP3',\n",
    "                '163Dy_CD56', \n",
    "                '164Dy_CD15', \n",
    "                '165Ho_pCREB S133', \n",
    "                '166Er_MPO',\n",
    "                '167Er_IL1-RAP', \n",
    "                '168Er_CD117', \n",
    "                '169Tm_CD33', \n",
    "                '170Er_pSRC Y418',\n",
    "                '171Yb_pERK T202Y204', \n",
    "                '172Yb_pS6 S235S236', \n",
    "                '173Yb_STAT3tot',\n",
    "                '174Yb_CD11c', \n",
    "                '175Lu_CXCR4', \n",
    "                '176Yb_pS6 S240244', \n",
    "                '195Pt_mBC2', \n",
    "                '209Bi_CD11b']    \n",
    "        \n",
    "\n",
    "external = ['89Y_CD45', \n",
    "                '111Cd_CD3', \n",
    "                '112Cd_CD34',\n",
    "                '113Cd_CD123', \n",
    "                '114Cd_CD66b', \n",
    "                '116Cd_HLA-DR', \n",
    "                '141Pr_CD38', \n",
    "                '145Nd_CD4', \n",
    "                '146Nd_CD49d', \n",
    "                '147Sm_CD20', \n",
    "                '148Nd_CD16', \n",
    "                '149Sm_CD25',\n",
    "                '152Sm_CD13',\n",
    "                '154Sm_CD45RA', \n",
    "                '155Gd_CD27',\n",
    "                '157Gd_CD8a', \n",
    "                '160Gd_CD14', \n",
    "                '161Dy_CD26', \n",
    "                '162Dy_FoxP3',\n",
    "                '163Dy_CD56', \n",
    "                '164Dy_CD15', \n",
    "                '166Er_MPO',\n",
    "                '167Er_IL1-RAP', \n",
    "                '168Er_CD117', \n",
    "                '169Tm_CD33', \n",
    "                '174Yb_CD11c', \n",
    "                '175Lu_CXCR4', \n",
    "                '195Pt_mBC2', \n",
    "                '209Bi_CD11b']\n",
    "\n",
    "internal = list(set(internal_and_external) - set(external))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[external]\n",
    "y = data['cluster']\n",
    "groups = data['sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "param_grid = [\n",
    "    {'solver': ['svd'], 'shrinkage': [None]},  \n",
    "    {'solver': ['lsqr', 'eigen'], 'shrinkage': [None, 'auto', 0.1, 0.5, 0.9]}\n",
    "]\n",
    "\n",
    "\n",
    "outer_cv = GroupKFold(n_splits=5)\n",
    "inner_cv = GroupKFold(n_splits=3)\n",
    "\n",
    "results = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    groups_train = groups.iloc[train_idx]\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=inner_cv,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train, groups=groups_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    predictions = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1_scores = f1_score(y_test, predictions, average=None)\n",
    "    median_f1 = np.median(f1_scores)\n",
    "\n",
    "    \n",
    "\n",
    "    true_frequencies = np.bincount(y_test) / len(y_test)\n",
    "    predicted_frequencies = np.bincount(predictions, minlength=len(np.unique(y))) / len(predictions)\n",
    "    max_diff = np.max(np.abs(true_frequencies - predicted_frequencies))\n",
    "    rsse = np.sqrt(np.sum((true_frequencies - predicted_frequencies) ** 2))\n",
    "\n",
    "    results.append({\n",
    "        'accuracy': accuracy,\n",
    "        'median_f1': median_f1,\n",
    "        'max_diff': max_diff,\n",
    "        'rsse': rsse,\n",
    "        'est': grid_search.best_score_,\n",
    "        'cfg': grid_search.best_params_\n",
    "    })\n",
    "\n",
    "    print('One round completed')\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_1 = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "outer_cv = GroupKFold(n_splits=5)\n",
    "\n",
    "results_1 = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(X, y, groups):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    groups_train = groups.iloc[train_idx]\n",
    "\n",
    "    model_1.fit(X_train, y_train)\n",
    "    predictions = model_1.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1_scores = f1_score(y_test, predictions, average=None)\n",
    "    median_f1 = np.median(f1_scores)\n",
    "\n",
    "    true_frequencies = np.bincount(y_test) / len(y_test)\n",
    "    predicted_frequencies = np.bincount(predictions, minlength=len(np.unique(y))) / len(predictions)\n",
    "    max_diff = np.max(np.abs(true_frequencies - predicted_frequencies))\n",
    "    rsse = np.sqrt(np.sum((true_frequencies - predicted_frequencies) ** 2))\n",
    "\n",
    "    results_1.append({\n",
    "        'accuracy': accuracy,\n",
    "        'median_f1': median_f1,\n",
    "        'max_diff': max_diff,\n",
    "        'rsse': rsse\n",
    "    })\n",
    "\n",
    "    print('One round completed')\n",
    "\n",
    "# Print results\n",
    "results_df_rfc = pd.DataFrame(results_1)\n",
    "print(results_df_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sample'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data[data['sample'].isin(['01_0', '01_1', '01_2',\n",
    "                                   '12_0', '12_1', '12_2',\n",
    "                                   '08_0', '08_1', '08_2',\n",
    "                                   '15_0', '15_1', '15_2',\n",
    "                                   '20_0', '20_1', '20_2',\n",
    "                                   '28_0', '28_1', '28_2',\n",
    "                                   '35_0', '35_1', '35_2',\n",
    "                                   'HDBM_663_None', 'HDPB_597_None', 'HDBM_578_None',])]\n",
    "\n",
    "data_train = data[~data['sample'].isin(['01_0', '01_1', '01_2',\n",
    "                                   '12_0', '12_1', '12_2',\n",
    "                                   '08_0', '08_1', '08_2',\n",
    "                                   '15_0', '15_1', '15_2',\n",
    "                                   '20_0', '20_1', '20_2',\n",
    "                                   '28_0', '28_1', '28_2',\n",
    "                                   '35_0', '35_1', '35_2',\n",
    "                                   'HDBM_663_None', 'HDPB_597_None', 'HDBM_578_None',])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "X = data_train[external]\n",
    "y = data_train['cluster']\n",
    "\n",
    "model_1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test[external]\n",
    "y_test = data_test['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "class_labels = [str(i) for i in range(19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.imshow(\n",
    "    cm_normalized,\n",
    "    text_auto=True,\n",
    "    labels=dict(x=\"Predicted Class\", y=\"Actual Class\", color=\"Normalized Count\"),\n",
    "    x=class_labels,\n",
    "    y=class_labels,\n",
    "    color_continuous_scale='Greens'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Normalized Confusion  for the annotated model\",\n",
    "    xaxis_title=\"Predicted Class\",\n",
    "    yaxis_title=\"Actual Class\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(\"Original Confusion Matrix\", \"Normalized Confusion Matrix\"),\n",
    "    horizontal_spacing=0.15  \n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=cm,\n",
    "        x=class_labels,\n",
    "        y=class_labels,\n",
    "        colorscale='Greens',\n",
    "        text=cm,\n",
    "        texttemplate=\"%{text}\",\n",
    "        showscale=True\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=cm_normalized,\n",
    "        x=class_labels,\n",
    "        y=class_labels,\n",
    "        colorscale='Greens',\n",
    "        text=np.round(cm_normalized, 2),\n",
    "        texttemplate=\"%{text}\",\n",
    "        showscale=True\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Confusion for the annotated model\",\n",
    "    xaxis_title=\"Predicted Class\",\n",
    "    yaxis_title=\"Actual Class\",\n",
    "    xaxis2_title=\"Predicted Class\",\n",
    "    yaxis2_title=\"Actual Class\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bruker trent modell til å predikere celle typene i pool2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pool_2 = pd.read_pickle('../cytofdata/uncorrected_batch_5_6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pool_2 = data_pool_2[~data_pool_2['file_id'].isin(['RT', 'RJ'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pool_2 = data_pool_2[external]\n",
    "y_pool_2 = model_1.predict(X_pool_2)\n",
    "\n",
    "data_pool_2['cluster'] = y_pool_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pool_2['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pool_2.to_pickle('../cytofdata/data_clusters_batch5_6_annotated_mode.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
